{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_recall_fscore_support\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"habanoz/classifier_1300_610_fetched\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['url', 'length', 'offset', 'filename', 'tag', 'src', 'label', 'raw', 'text'],\n",
       "        num_rows: 11462\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_org = ds['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import urllib.parse\n",
    "\n",
    "def prep_url(url):\n",
    "    url = urllib.parse.unquote(url)\n",
    "\n",
    "    # Find the index of the first occurrence of \"//\"\n",
    "    protocol_end_index = url.find(\"://\") + 3\n",
    "\n",
    "    # Find the index of the first occurrence of \"/\" after the protocol\n",
    "    domain_end_index = url.find(\"/\", protocol_end_index)+1\n",
    "\n",
    "    # Extract the path and query components\n",
    "    url = url[domain_end_index:]\n",
    "\n",
    "    url = re.sub(r\"\\b[2][0]\\d{2}\\b\",\"<year>\",url)\n",
    "    url = re.sub(r\"\\b[1][9]\\d{2}\\b\",\"<year>\",url)\n",
    "    url = re.sub(r\"\\b[1-9][0-9]{3,}\\b\",\"<number>\",url)\n",
    "    url = re.sub(r\"\\b[1-9][0-9]{2}\\b\",\"<3number>\",url)\n",
    "    url = re.sub(r\"\\b[1-9][0-9]\\b\",\"<2number>\",url)\n",
    "    \n",
    "    return url\n",
    "\n",
    "def process_row(row):\n",
    "    url = row.url\n",
    "    row['url_p'] = prep_url(url)\n",
    "    return row \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_org.apply(process_row, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create private test set and training set\n",
    "private_test = df[df['url'].str.contains('aljazeera', case=False)]\n",
    "train_data = df[~df['url'].str.contains('aljazeera', case=False)]\n",
    "\n",
    "# Split the training data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    train_data['url_p'], train_data['label'], test_size=0.1, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push to Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b247287f2a734bf781df92bd1fd55d6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47a4233a5a28466482640af76946f045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c694c722525c4fe0a191b88dc4ee76d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/habanoz/classifier_1300_610_url_p/commit/d9daf1a6c08292db50e74631aa91f62732b42f24', commit_message='Upload dataset', commit_description='', oid='d9daf1a6c08292db50e74631aa91f62732b42f24', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ds.push_to_hub(\"habanoz/classifier_1300_610_url_p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dict = DatasetDict({\n",
    "    \"train\":Dataset.from_pandas(pd.concat([X_train, y_train],axis=1)).remove_columns(\"__index_level_0__\"),\n",
    "    \"validation\":Dataset.from_pandas(pd.concat([X_val, y_val],axis=1)).remove_columns(\"__index_level_0__\"),\n",
    "    \"test\":Dataset.from_pandas(private_test[['url_p','label']]).remove_columns(\"__index_level_0__\"),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b8e8b8995a54d78857cb6e61b765c9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b14e05838384d7fb40e59363608b99d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e2c6408a1d644ef912aa946e5605a99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdfa19a9b0d24ee6a2652fc7da1a05fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d4ebd0b3e804db2b0a8f023ba51a34d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67bfef1d3c3847639a4bc895df1926dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/habanoz/classifier_1300_610_url_p_svc_training_splits/commit/1ba4fcd98366f450d94a0a73d86f7ca7b68400cb', commit_message='Upload dataset', commit_description='', oid='1ba4fcd98366f450d94a0a73d86f7ca7b68400cb', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ds_dict.push_to_hub(\"habanoz/classifier_1300_610_url_p_svc_training_splits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train an SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       547\n",
      "           1       0.99      1.00      0.99       478\n",
      "\n",
      "    accuracy                           1.00      1025\n",
      "   macro avg       0.99      1.00      1.00      1025\n",
      "weighted avg       1.00      1.00      1.00      1025\n",
      "\n",
      "Validation Accuracy: 0.9951\n",
      "Private Test Set Accuracy: 0.9352\n",
      "Other Private Test Set Metrics: (array([0.91811024, 0.95384615]), array([0.9557377, 0.9147541]), array([0.93654618, 0.93389121]), array([610, 610]))\n"
     ]
    }
   ],
   "source": [
    "# Feature extraction\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,3))\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_val_vectorized = vectorizer.transform(X_val)\n",
    "X_private_test_vectorized = vectorizer.transform(private_test['url_p'])\n",
    "\n",
    "clf = SVC(kernel='rbf',C=20, gamma=0.1)\n",
    "clf.fit(X_train_vectorized, y_train)\n",
    "y_val_pred = clf.predict(X_val_vectorized)\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Evaluate the best classifier on the private test set\n",
    "y_private_test_pred = clf.predict(X_private_test_vectorized)\n",
    "private_test_accuracy = accuracy_score(private_test['label'], y_private_test_pred)\n",
    "private_precision_recall_fscore_support = precision_recall_fscore_support(private_test['label'], y_private_test_pred)\n",
    "print(f\"Private Test Set Accuracy: {private_test_accuracy:.4f}\")\n",
    "print(f\"Other Private Test Set Metrics: {private_precision_recall_fscore_support}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../.models/news_vectorizer.joblib']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not os.path.exists(\"../.models\"):\n",
    "    os.mkdir(\"../.models\")\n",
    "joblib.dump(clf, '../.models/news_classifier.joblib')\n",
    "joblib.dump(vectorizer, '../.models/news_vectorizer.joblib')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed URL: hava-durumu/kuzey-amerika/amerika-birlesik-devletleri/wi/cesme-sehir\n",
      "\n",
      "The URL https://tr.euronews.com/hava-durumu/kuzey-amerika/amerika-birlesik-devletleri/wi/cesme-sehir is classified as: 0\n",
      "Processed URL: video/kaplan-tapinaginda-<2number>-kaplan-yavrusunun-olusu-bulundu,<number>\n",
      "\n",
      "The URL https://t24.com.tr/video/kaplan-tapinaginda-40-kaplan-yavrusunun-olusu-bulundu,2279 is classified as: 1\n",
      "Processed URL: yazarlar/bekir-agirdir/sorun-cozme-kapasitesi-dusuk-ulke,<number>\n",
      "\n",
      "The URL https://www.t24.com.tr/yazarlar/bekir-agirdir/sorun-cozme-kapasitesi-dusuk-ulke,33689 is classified as: 1\n"
     ]
    }
   ],
   "source": [
    "loaded_vectorizer = joblib.load('../.models/news_vectorizer.joblib')\n",
    "loaded_cls = joblib.load('../.models/news_classifier.joblib')\n",
    "\n",
    "def classify_url(url):\n",
    "    url = prep_url(url)\n",
    "    print(f\"Processed URL: {url}\")\n",
    "    url_vectorized = loaded_vectorizer.transform([url])\n",
    "    return loaded_cls.predict(url_vectorized)[0]\n",
    "\n",
    "# Example usage\n",
    "new_urls = [\"https://tr.euronews.com/hava-durumu/kuzey-amerika/amerika-birlesik-devletleri/wi/cesme-sehir\",\"https://t24.com.tr/video/kaplan-tapinaginda-40-kaplan-yavrusunun-olusu-bulundu,2279\",\"https://www.t24.com.tr/yazarlar/bekir-agirdir/sorun-cozme-kapasitesi-dusuk-ulke,33689\"]\n",
    "for new_url in new_urls:\n",
    "    prediction = classify_url(new_url)\n",
    "    print(f\"\\nThe URL {new_url} is classified as: {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ead9896d4f499e977f0be175de35c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/518 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "666230ef71cf4139b9676144b1a9cc24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/337k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83774cb6035f40c08e296d5f6cafa111",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/37.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c658bfab95648dfaee83ca8d09c6bea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/29.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a02f2d87611d45958dfe8e48eadf9ea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/9217 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcdbaa29d41f49ffaa7790788352012e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1025 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02aab02c36264b949ed2c49e770f6191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1220 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "svc_ds = load_dataset(\"habanoz/classifier_1300_610_url_p_svc_training_splits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Private Test Set Accuracy: 0.9352\n"
     ]
    }
   ],
   "source": [
    "loaded_vectorizer = joblib.load('../.models/news_vectorizer.joblib')\n",
    "loaded_cls = joblib.load('../.models/news_classifier.joblib')\n",
    "X_private_test_vectorized = loaded_vectorizer.transform(svc_ds['test']['url_p'])\n",
    "\n",
    "y_private_test_pred = loaded_cls.predict(X_private_test_vectorized)\n",
    "private_test_accuracy = accuracy_score(svc_ds['test']['label'], y_private_test_pred)\n",
    "print(f\"Private Test Set Accuracy: {private_test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
